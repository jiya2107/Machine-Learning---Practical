{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMYI6XwXHzkJGr1K9GP9D+F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jiya2107/Machine-Learning---Practical/blob/main/ML_Experiment_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQCn6m0aqU3E"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Load and preprocess data (same as experiment 3, but keep PROT as target)\n",
        "try:\n",
        "    df = pd.read_csv('HepatitisCdata.csv', index_col=0)\n",
        "except FileNotFoundError:\n",
        "    print(\"Please ensure 'HepatitisCdata.csv' is uploaded.\")\n",
        "    exit()\n",
        "\n",
        "df = df.replace('?', np.nan)\n",
        "for col in df.columns:\n",
        "    if col != 'Category' and col != 'Sex':\n",
        "        df[col] = pd.to_numeric(df[col])\n",
        "df = df.dropna()\n",
        "df['Sex'] = df['Sex'].map({'m': 1, 'f': 0})\n",
        "df = df.drop('Category', axis=1) # Drop classification target\n",
        "\n",
        "# Define X and y for regression (Predicting PROT)\n",
        "X = df.drop('PROT', axis=1)\n",
        "y = df['PROT']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "def evaluate_model(model, X_test, y_test, model_name):\n",
        "    y_pred = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    print(f\"\\n--- {model_name} Results ---\")\n",
        "    print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
        "    print(f\"R-squared (R2): {r2:.2f}\")\n",
        "    try:\n",
        "        # For regularized models, show some coefficients\n",
        "        print(\"Coefficients (Sample):\")\n",
        "        for feature, coef in zip(X.columns, model.coef_):\n",
        "            if abs(coef) > 0.01: # Print significant ones\n",
        "                print(f\"  {feature}: {coef:.3f}\")\n",
        "    except AttributeError:\n",
        "        pass # LinearRegression.coef_ is standard\n",
        "\n",
        "# --- 1. Linear Regression (No Regularization) ---\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_train_scaled, y_train)\n",
        "evaluate_model(lin_reg, X_test_scaled, y_test, \"Linear Regression\")\n",
        "\n",
        "# --- 2. Ridge Regression (L2 Regularization) ---\n",
        "# alpha is the regularization strength (lambda)\n",
        "ridge_reg = Ridge(alpha=10.0) # Using a moderate alpha\n",
        "ridge_reg.fit(X_train_scaled, y_train)\n",
        "evaluate_model(ridge_reg, X_test_scaled, y_test, f\"Ridge Regression (L2, alpha=10.0)\")\n",
        "\n",
        "# --- 3. Lasso Regression (L1 Regularization) ---\n",
        "# alpha is the regularization strength (lambda)\n",
        "lasso_reg = Lasso(alpha=0.1) # Using an alpha that might enforce sparsity\n",
        "lasso_reg.fit(X_train_scaled, y_train)\n",
        "evaluate_model(lasso_reg, X_test_scaled, y_test, f\"Lasso Regression (L1, alpha=0.1)\")\n",
        "\n",
        "print(\"\\nNote: Lasso (L1) can drive some coefficients exactly to zero, performing feature selection.\")"
      ]
    }
  ]
}